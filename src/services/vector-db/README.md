# üîç Vector DB Service - B√∫squeda Sem√°ntica

Servicio de b√∫squeda vectorial para encontrar unicornios similares usando embeddings.

## üì¶ Instalaci√≥n

```bash
cd src/services/vector-db
pip install -r requirements.txt
```

En la primera ejecuci√≥n, descargar√° el modelo `all-MiniLM-L6-v2` (~80MB).

## ‚öôÔ∏è Configuraci√≥n

1. Copia `.env.example` a `.env`:
```bash
cp .env.example .env
```

2. Edita `.env`:
```env
MONGODB_URI=mongodb://localhost:27017/Unicornio
EMBEDDING_MODEL=all-MiniLM-L6-v2
VECTOR_INDEX_PATH=./vector_index
ENVIRONMENT=development
```

## üöÄ Ejecuci√≥n

```bash
# Desde src/services/vector-db/
uvicorn app:app --port 7000
```

**‚ö†Ô∏è Importante**: No uses `--reload` en producci√≥n, para mantener el √≠ndice en memoria.

El servicio estar√° disponible en: `http://localhost:7000`

## üì° Endpoints

### `GET /health`
Health check del servicio.

**Response:**
```json
{
  "status": "OK",
  "message": "Vector DB funcionando correctamente",
  "embedding_model": "all-MiniLM-L6-v2",
  "index_status": "Loaded",
  "indexed_documents": 1305
}
```

### `POST /build-index`
Construye el √≠ndice vectorial desde MongoDB.

**Cu√°ndo usar:**
- Primera vez que inicias el servicio
- Cuando agregues nuevos unicornios a MongoDB
- Para actualizar el √≠ndice con datos recientes

**Response:**
```json
{
  "success": true,
  "message": "√çndice vectorial construido exitosamente",
  "total_documents": 1305,
  "embedding_dim": 384
}
```

**Tiempo estimado:** ~30 segundos para 1,000 documentos.

### `POST /search`
Busca proyectos similares por similitud sem√°ntica.

**Body:**
```json
{
  "query": "Plataforma de delivery de alimentos con inteligencia artificial",
  "top_k": 5
}
```

**Response:**
```json
{
  "query": "Plataforma de delivery de alimentos...",
  "results": [
    {
      "nombre": "Rappi",
      "sector": "Delivery",
      "pais": "Colombia",
      "valoracion": 5200000000,
      "etapa": "unicornio",
      "descripcion": "...",
      "similarity": 0.87
    },
    {
      "nombre": "DoorDash",
      "sector": "Delivery",
      "pais": "United States",
      "valoracion": 72000000000,
      "etapa": "decacornio",
      "descripcion": "...",
      "similarity": 0.82
    }
  ],
  "total_found": 5
}
```

**Similarity score:**
- `0.9 - 1.0`: Muy similar
- `0.7 - 0.9`: Similar
- `0.5 - 0.7`: Moderadamente similar
- `< 0.5`: Poco similar

### `POST /load-index`
Carga un √≠ndice previamente guardado desde disco.

√ötil para reiniciar el servicio sin reconstruir el √≠ndice.

## üîß C√≥mo Funciona

### 1. Construcci√≥n del √≠ndice:

```
MongoDB (unicornios) ‚Üí Textos ‚Üí Embeddings ‚Üí FAISS Index
```

- Lee todos los unicornios de MongoDB
- Para cada uno, crea un texto: `nombre + sector + descripci√≥n + pa√≠s`
- Genera embeddings usando `all-MiniLM-L6-v2` (384 dimensiones)
- Crea un √≠ndice FAISS para b√∫squeda r√°pida
- Guarda en disco para cargas futuras

### 2. B√∫squeda:

```
Query ‚Üí Embedding ‚Üí FAISS Search ‚Üí Top K Results
```

- Convierte la query en embedding
- Busca en el √≠ndice FAISS usando similitud de coseno
- Retorna los K resultados m√°s similares con scores

## üìä Modelo de Embeddings

**all-MiniLM-L6-v2** (Sentence Transformers):
- ‚úÖ Ligero: ~80MB
- ‚úÖ R√°pido: ~1000 embeddings/segundo en CPU
- ‚úÖ Buena calidad para b√∫squeda sem√°ntica
- ‚úÖ Multilenguaje (incluye espa√±ol)
- üìè Dimensiones: 384

**Alternativas:**
- `paraphrase-multilingual-MiniLM-L12-v2` (m√°s precisi√≥n)
- `distiluse-base-multilingual-cased-v2` (mejor multilenguaje)

## üß™ Testing

```bash
# Health check
curl http://localhost:7000/health

# Construir √≠ndice
curl -X POST http://localhost:7000/build-index

# Buscar similares
curl -X POST http://localhost:7000/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "aplicaci√≥n de comercio electr√≥nico para peque√±as empresas",
    "top_k": 5
  }'
```

## üíæ Persistencia

El √≠ndice se guarda autom√°ticamente en `./vector_index/`:
- `index.faiss`: √çndice FAISS
- `metadata.pkl`: Datos de los unicornios
- `embeddings.pkl`: Cache de embeddings

Al reiniciar el servicio, carga autom√°ticamente el √≠ndice guardado.

## üöÄ Optimizaci√≥n

**Para grandes vol√∫menes (>100K documentos):**

1. Cambiar a `IndexIVFFlat` en lugar de `IndexFlatIP`
2. Usar GPU con `faiss-gpu`
3. Implementar b√∫squeda aproximada (ANN)

**Ejemplo con IVF:**
```python
quantizer = faiss.IndexFlatIP(dimension)
faiss_index = faiss.IndexIVFFlat(quantizer, dimension, 100)  # 100 clusters
faiss_index.train(embeddings)
faiss_index.add(embeddings)
```

## üìù Notas

- El √≠ndice se mantiene en memoria para b√∫squedas r√°pidas
- Reconstruye el √≠ndice cuando agregues nuevos unicornios
- Compatible con CPU y GPU (cambia `faiss-cpu` por `faiss-gpu`)
- Escalable a millones de documentos con configuraciones avanzadas
